---
# restek.core.eks_delete_cluster collection playbook
# ansible-playbook -e "@$HOME/flux/clusters/$CLUSTER_NAME.values.yaml" restek.core.eks_delete_cluster
# python3 -m pip install kubernetes
#
- name: AWS EKS delete cluster
  hosts: localhost
  become: false
  connection: local
  vars:
    aws_profile: default
    # cluster_name: ""
    flux_dir: "{{ (lookup('ansible.builtin.env', 'HOME'), 'flux') | path_join }}"
    purge: false
    namespaces:
      - ack-system
      - calico-system
      - default
      - flux-system
      - kube-node-lease
      - kube-public
      - kube-system
      - tigera-operator

  pre_tasks:
    - name: Mandatory variables?
      ansible.builtin.assert:
        that:
          - cluster_name is defined and cluster_name is regex("^[a-z0-9][a-z0-9-]+")

  tasks:
    - name: Get AWS region
      ansible.builtin.command:
        cmd: aws configure get region --profile {{ aws_profile }}
      changed_when: false
      register: region_output

    - name: Get AWS account ID
      ansible.builtin.command:
        cmd: aws sts get-caller-identity --profile {{ aws_profile }} --output text --query 'Account'
      changed_when: false
      register: aws_account_id_output

    - name: Set facts
      ansible.builtin.set_fact:
        account_id: "{{ aws_account_id_output.stdout }}"
        region: "{{ region_output.stdout }}"
        stack_name: eksctl-{{ cluster_name }}-cluster

    - name: EFS delete
      when:
        - purge
      amazon.aws.cloudformation:
        profile: "{{ aws_profile }}"
        stack_name: eks-{{ cluster_name }}-efs-csi
        state: absent

    - name: EFS disconnect
      when:
        - not purge
      amazon.aws.cloudformation:
        on_create_failure: ROLLBACK
        profile: "{{ aws_profile }}"
        stack_name: eks-{{ cluster_name }}-efs-csi
        state: present
        template_parameters:
          Environment: {use_previous_value: true}
          TransitionToIA: {use_previous_value: true}
          PerformanceMode: {use_previous_value: true}
          VpcId: {use_previous_value: true}
          SecurityGroupId: "sg-00000000000000000"
          SubnetId1: "subnet-00000000000000000"
          SubnetId2: "subnet-00000000000000000"
          SubnetId3: "subnet-00000000000000000"

    - name: EKS cluster exists?
      ansible.builtin.command:
        cmd: aws eks list-clusters --output json
      register: list_clusters
      changed_when: false

    - name: EKS cluster stack?
      amazon.aws.cloudformation_info:
        profile: "{{ aws_profile }}"
        stack_name: "{{ stack_name }}"
      register: eks_stack

    - name: Delete EKS cluster
      when: "cluster_name in (list_clusters.stdout | from_json).clusters"
      block:
        - name: Get kubectl config
          ansible.builtin.command:
            cmd: >
              aws eks update-kubeconfig --name {{ cluster_name }}
              --profile {{ aws_profile }}
              --kubeconfig /dev/null --dry-run
          register: kubeconfig_output
          changed_when: false

        # TODO: Verify vpc_id after linting issue resolution
        - name: Set Facts
          ansible.builtin.set_fact:
            kubeconfig: "{{ kubeconfig_output.stdout | from_yaml }}"
            vpc_id: >-
              {{ eks_stack[stack_name]['stack_description']['outputs'] |
              selectattr('output_key', 'equalto', 'VPC') |
              map(attribute='output_value') | first }}

        - name: K8s info?
          kubernetes.core.k8s_info:
            kind: Namespace
            kubeconfig: "{{ kubeconfig }}"
          register: k8s_info_reg
        # - ansible.builtin.debug: {var: k8s_info_reg}
        # - ansible.builtin.debug: {var: k8s_info_reg.resources | map(attribute='metadata.name') | list}

        - name: Guardduty agent?
          ansible.builtin.command:
            cmd: >-
              aws eks list-addons
              --cluster-name {{ cluster_name }}
              --profile {{ aws_profile }}
              --output json
          register: addons_list
          changed_when: false

        - name: Delete addon aws-guardduty-agent
          when: "'aws-guardduty-agent' in (addons_list.stdout | from_json).addons"
          ansible.builtin.command:
            cmd: >-
              aws eks delete-addon
              --cluster-name {{ cluster_name }}
              --addon-name aws-guardduty-agent
              --profile {{ aws_profile }}
              --output json
          register: guardduty_agent
          changed_when: "(guardduty_agent.stdout | from_json).addon.status == 'DELETING'"

        # GuardDuty
        # aws ec2 delete-vpc-endpoints --vpc-endpoint-ids vpce-#################
        # aws ec2 describe-security-groups \
        # --filters Name=tag:GuardDutyManaged,Values=true Name=vpc-id,Values=vpc-################# \
        # --query 'SecurityGroups[].GroupId' --output text \
        # |xargs -n1 aws ec2 delete-security-group --group-id
        - name: GuardDuty VPC endpoint?
          amazon.aws.ec2_vpc_endpoint_info:
            filters:
              "tag:GuardDutyManaged": true
              vpc-id: "{{ vpc_id }}"
            profile: "{{ aws_profile }}"
          register: guardduty_vpc_endpoint

        - name: GuardDuty VPC endpoint
          amazon.aws.ec2_vpc_endpoint:
            profile: "{{ aws_profile }}"
            state: absent
            vpc_endpoint_id: "{{ guardduty_vpc_endpoint.vpc_endpoints | map(attribute='vpc_endpoint_id') | list }}"

        - name: GuardDuty Security Group
          amazon.aws.ec2_security_group_info:
            filters:
              "tag:GuardDutyManaged": true
              vpc-id: "{{ vpc_id }}"
            profile: "{{ aws_profile }}"
          register: guardduty_security_group

        - name: GuardDuty Security Group
          amazon.aws.ec2_security_group:
            group_id: "{{ guardduty_security_group.security_groups | map(attribute='group_id') | list }}"
            profile: "{{ aws_profile }}"
            state: absent

        - name: Delete kubernetes resources
          kubernetes.core.k8s:
            kind: Namespace
            kubeconfig: "{{ kubeconfig }}"
            name: "{{ item }}"
            state: absent
          loop: >-
            {{ k8s_info_reg.resources |
            map(attribute='metadata.name') |
            list |
            difference(namespaces) }}"

        # TODO Services using the LB with public IP need to be removed before cluster deleted

        # - name: Verify empty Kubernetes cluster
        #   when:
        #     - k8s_info_reg.resources | map(attribute='metadata.name') | list |
        #       difference(namespaces) |
        #       length > 0
        #   ansible.builtin.fail:
        #     msg: Kubernetes is running workloads. Remove these services before decomissioning the cluster.

        # - name: EKS stacks exist?
        #   ansible.builtin.command:
        #     cmd: >-
        #       aws cloudformation list-stacks
        #       --query 'StackSummaries[?starts_with(StackName,`eksctl-{{ cluster_name }}-cluster`)==`true`]|[].StackName'
        #       --profile {{ aws_profile }}
        #       --output json

        # aws ec2 delete-security-group --group-id sg-#################
        # aws ec2 delete-vpc-endpoints --vpc-endpoint-ids vpce-#################
        - name: Delete EKS cluster
          ansible.builtin.command:
            cmd: >
              eksctl delete cluster
              --wait
              --config-file "{{ flux_dir }}/clusters/{{ cluster_name }}.eks.yaml"
              --profile {{ aws_profile }}
          register: eks_delete
          changed_when: false
        # - ansible.builtin.debug: {var: eks_delete}

    - name: KMS key delete
      when:
        - purge
      amazon.aws.kms_key:
        alias: eks-secrets-{{ cluster_name }}
        profile: "{{ aws_profile }}"
        state: absent

    - name: Karpenter stack delete
      amazon.aws.cloudformation:
        profile: "{{ aws_profile }}"
        stack_name: Karpenter-{{ cluster_name }}
        state: absent

    - name: Flux settings delete
      when:
        - 0 > 1
        - purge
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      with_items:
        - "{{ flux_dir }}/apps/overlays/{{ cluster_name }}"
        - "{{ flux_dir }}/infrastructure/overlays/{{ cluster_name }}"
        - "{{ flux_dir }}/clusters/{{ cluster_name }}"
