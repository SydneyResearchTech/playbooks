---
# restek.core.eks_delete_cluster collection playbook
# ansible-playbook -e "@$HOME/flux/clusters/$CLUSTER_NAME.values.yaml" restek.core.eks_delete_cluster
# python3 -m pip install kubernetes
- name: AWS EKS delete cluster
  hosts: localhost
  become: false
  connection: local
  vars:
    aws_profile: default
    # cluster_name: ""
    flux_dir: "{{ (lookup('ansible.builtin.env', 'HOME'), 'flux') | path_join }}"
    purge: false
    namespaces:
      - ack-system
      - amazon-guardduty
      - calico-system
      - default
      - flux-system
      - kube-node-lease
      - kube-public
      - kube-system
      - tigera-operator

  handlers:
    - name: Delete tempfile
      when:
        - kubeconfig_file.path is defined
      ansible.builtin.file:
        path: "{{ kubeconfig_file.path }}"
        status: absent

  pre_tasks:
    - name: Mandatory variables?
      ansible.builtin.assert:
        that:
          - cluster_name is defined and cluster_name is regex("^[a-z0-9][a-z0-9-]+")

  tasks:
    - name: Get AWS region
      ansible.builtin.command:
        cmd: aws configure get region --profile {{ aws_profile }}
      changed_when: false
      register: region_output

    - name: Get AWS account ID
      ansible.builtin.command:
        cmd: aws sts get-caller-identity --profile {{ aws_profile }} --output text --query 'Account'
      changed_when: false
      register: aws_account_id_output

    - name: Get EKS clusters
      ansible.builtin.command:
        cmd: aws eks list-clusters --profile={{ aws_profile }} --output=json
      register: list_clusters
      changed_when: false

    - name: Get kubectl config
      ansible.builtin.command:
        cmd: >
          aws eks update-kubeconfig --dry-run
          --name={{ cluster_name }}
          --profile={{ aws_profile }}
          --kubeconfig=/dev/null
      register: kubeconfig_reg
      changed_when: false
      ignore_errors: true

    - name: Set facts
      ansible.builtin.set_fact:
        account_id: "{{ aws_account_id_output.stdout }}"
        region: "{{ region_output.stdout }}"
        stack_name: eksctl-{{ cluster_name }}-cluster
        kubeconfig: >-
          {{ (cluster_name in (list_clusters.stdout | from_json).clusters) |
          ternary((kubeconfig_reg.stdout | from_yaml), '') }}

    - name: mktemp
      ansible.builtin.tempfile:
        state: file
      register: kubeconfig_file
      notify:
        - Delete tempfile
    - name: Create kubeconfig file
      ansible.builtin.copy:
        content: "{{ kubeconfig | to_json }}"
        dest: "{{ kubeconfig_file.path }}"
        mode: "0600"

    - name: If cluster exists
      when:
        - kubeconfig | length > 0
      block:
        - name: Get kubernetes resources
          ansible.builtin.set_fact:
            kuberentes_sc: "{{ query('kubernetes.core.k8s', kind='StorageClass', kubeconfig=kubeconfig_file.path) }}"
            kubernetes_ns: "{{ query('kubernetes.core.k8s', kind='Namespace', kubeconfig=kubeconfig_file.path) }}"
            kubernetes_pv: "{{ query('kubernetes.core.k8s', kind='PersistentVolume', kubeconfig=kubeconfig_file.path) }}"

        - name: Uninstall flux
          ansible.builtin.command:
            cmd: >-
              flux uninstall --silent
              --kubeconfig='{{ kubeconfig_file.path }}'

        - name: Resources require attention
          ansible.builtin.assert:
            fail_msg: >
              Namespace={{ kubernetes_ns | map(attribute='metadata.name') | list | difference(namespaces) | list }}
              PersistentVolumes={{ kubernetes_pv | map(attribute='metadata.name') | list }}
            success_msg: >
              Continue...
            that:
              - kubernetes_pv | length <= 0
              - kubernetes_ns | map(attribute='metadata.name') | list |
                difference(namespaces) | list | length <= 0

        - name: Delete efs.csi.aws.com storage class
          kubernetes.core.k8s:
            api_version: storage.k8s.io/v1
            kind: StorageClass
            kubeconfig: "{{ kubeconfig }}"
            name: "{{ item.metadata.name }}"
            state: absent
          loop: "{{ kuberentes_sc | selectattr('provisioner', 'equalto', 'efs.csi.aws.com') }}"

    # aws efs describe-mount-targets --file-system-id fs-0aa729b6459886642
    - name: Delete EFS stack
      when:
        - purge
      amazon.aws.cloudformation:
        profile: "{{ aws_profile }}"
        stack_name: eks-{{ cluster_name }}-efs-csi
        state: absent

    - name: EFS disconnect
      when:
        - not purge
      amazon.aws.cloudformation:
        on_create_failure: ROLLBACK
        profile: "{{ aws_profile }}"
        stack_name: eks-{{ cluster_name }}-efs-csi
        state: present
        template_parameters:
          Environment: {use_previous_value: true}
          TransitionToIA: {use_previous_value: true}
          PerformanceMode: {use_previous_value: true}
          VpcId: {use_previous_value: true}
          SecurityGroupId: 'AWS::NoValue'
          SubnetId1: 'AWS::NoValue'
          SubnetId2: 'AWS::NoValue'
          SubnetId3: 'AWS::NoValue'

    - name: If eks cluster exists
      when:
        - kubeconfig | length > 0
      block:
        - name: Get eks addons
          ansible.builtin.command:
            cmd: >-
              aws eks list-addons
              --cluster-name {{ cluster_name }}
              --profile {{ aws_profile }}
              --output json
          register: addons_list_reg
          changed_when: false

        - name: Delete addon aws-guardduty-agent
          when:
            - "'aws-guardduty-agent' in (addons_list_reg.stdout | from_json).addons"
          ansible.builtin.command:
            cmd: >-
              aws eks delete-addon
              --cluster-name {{ cluster_name }}
              --addon-name aws-guardduty-agent
              --profile {{ aws_profile }}
              --output json
          register: guardduty_agent
          changed_when: "(guardduty_agent.stdout | from_json).addon.status == 'DELETING'"

    - name: Get eks stack info
      amazon.aws.cloudformation_info:
        profile: "{{ aws_profile }}"
        stack_name: "{{ stack_name }}"
      register: eks_stack_reg
      ignore_errors: true

    - name: If eks stack exists
      when:
        - not eks_stack_reg.failed
        - eks_stack_reg.cloudformation | length > 0
      block:
        - name: Set facts
          ansible.builtin.set_fact:
            vpc_id: >-
              {{ eks_stack_reg['cloudformation'][stack_name]['stack_description']['outputs'] |
              selectattr('output_key', 'equalto', 'VPC') |
              map(attribute='output_value') | first }}

        # GuardDuty
        # aws ec2 delete-vpc-endpoints --vpc-endpoint-ids vpce-#################
        # aws ec2 describe-security-groups \
        # --filters Name=tag:GuardDutyManaged,Values=true Name=vpc-id,Values=vpc-################# \
        # --query 'SecurityGroups[].GroupId' --output text \
        # |xargs -n1 aws ec2 delete-security-group --group-id
        - name: Get GuardDuty VPC endpoint
          amazon.aws.ec2_vpc_endpoint_info:
            filters:
              "tag:GuardDutyManaged": true
              vpc-id: "{{ vpc_id }}"
            profile: "{{ aws_profile }}"
          register: guardduty_vpc_endpoint
        # - ansible.builtin.debug: {var: guardduty_vpc_endpoint}

        - name: Delete GuardDuty VPC endpoint
          amazon.aws.ec2_vpc_endpoint:
            profile: "{{ aws_profile }}"
            state: absent
            vpc_endpoint_id: "{{ item.vpc_endpoint_id }}"
            wait: true
          loop: "{{ guardduty_vpc_endpoint.vpc_endpoints }}"

        - name: Wait for vpc endpoint delete operation
          amazon.aws.ec2_vpc_endpoint_info:
            filters:
              "tag:GuardDutyManaged": true
              vpc-id: "{{ vpc_id }}"
            profile: "{{ aws_profile }}"
          register: guardduty_vpc_endpoint_status
          until: guardduty_vpc_endpoint_status.vpc_endpoints | length == 0
          retries: 30
          delay: 10

        - name: Get GuardDuty Security Group
          amazon.aws.ec2_security_group_info:
            filters:
              "tag:GuardDutyManaged": true
              vpc-id: "{{ vpc_id }}"
            profile: "{{ aws_profile }}"
          register: guardduty_security_group
        # - ansible.builtin.debug: {var: guardduty_security_group}

        - name: Delete GuardDuty Security Group
          amazon.aws.ec2_security_group:
            group_id: "{{ item.group_id }}"
            profile: "{{ aws_profile }}"
            state: absent
          loop: "{{ guardduty_security_group.security_groups }}"

        # RDS Security group "GroupName": "eks-restek-uat-vpc-rds-access"

        # TODO Services using the LB with public IP need to be removed before cluster deleted

        # - name: Verify empty Kubernetes cluster
        #   when:
        #     - k8s_info_reg.resources | map(attribute='metadata.name') | list |
        #       difference(namespaces) |
        #       length > 0
        #   ansible.builtin.fail:
        #     msg: Kubernetes is running workloads. Remove these services before decomissioning the cluster.

        # - name: EKS stacks exist?
        #   ansible.builtin.command:
        #     cmd: >-
        #       aws cloudformation list-stacks
        #       --query 'StackSummaries[?starts_with(StackName,`eksctl-{{ cluster_name }}-cluster`)==`true`]|[].StackName'
        #       --profile {{ aws_profile }}
        #       --output json

        # aws ec2 delete-security-group --group-id sg-#################
        # aws ec2 delete-vpc-endpoints --vpc-endpoint-ids vpce-#################
        - name: Delete EKS cluster
          ansible.builtin.command:
            cmd: >
              eksctl delete cluster
              --name {{ cluster_name }}
              --wait
              --profile {{ aws_profile }}
          register: eks_delete
          changed_when: false
        # - ansible.builtin.debug: {var: eks_delete}

    - name: Delete KMS key
      when:
        - purge
      amazon.aws.kms_key:
        alias: eks-secrets-{{ cluster_name }}
        profile: "{{ aws_profile }}"
        state: absent

    - name: Delete karpenter stack
      amazon.aws.cloudformation:
        profile: "{{ aws_profile }}"
        stack_name: Karpenter-{{ cluster_name }}
        state: absent

    - name: Delete flux settings
      when:
        - 0 > 1
        - purge
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      with_items:
        - "{{ flux_dir }}/apps/overlays/{{ cluster_name }}"
        - "{{ flux_dir }}/infrastructure/overlays/{{ cluster_name }}"
        - "{{ flux_dir }}/clusters/{{ cluster_name }}"
